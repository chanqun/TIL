# 대규모 서비스를 지탱하는 기술

## 1. 대규모 웹 서비스 개발 오리엔테이션

### 강의 0 이 책의 근간

사용자가 이용하고 있는 대규모 서비스에 변경을 가할 때 규모를 고려하지 않고 어중간하게 구현해서 적용하다 보면, 어이없게도 아주 간단히 시스템 정지를 초래할 수 있음

- 대규모 웹 서비스 개발이란?
- 대규모 데이터를 다룰 때의 과제, 다루기 위한 기본적인 사고방식과 요령 (OS의 캐시 기능, 대규모 데이터를 전제로 한 DB운용)
- 알고리즘과 데이터 구조 선택의 중요성, (대규모 데이터)
- RDBMS로 모두 다룰 수 없는 규모의 데이터 처리방법 (검색 엔진)
- 대규모 서비스가 될 것을 전제로 한 서버/인프라 시스템의 예와 개념

### 강의 1 대규모 서비스와 소규모 서비스

- 등록 사용자는 100만 명 이상, 1500만명 UU
- 수십 억 액세스/월
- 피크 시 회선 트래픽 430Mbps
- 하드웨어 서버 500대 이상


#### 소규모 서비스와 대규모 서비스의 차이

##### 확장성 확보, 부하분산 필요

스케일 아웃 - 서버를 횡으로 전개, 즉 서버의 역할을 분담하거나 대수를 늘림으로써 시스템의 전체적인 처리능력을 높여서 부하를 분산하는 방법
스케일 업 - 하드웨어의 성능을 높여 처리능력을 끌어올리는 방법

사용자로부터의 요청을 어떻게 분배할 것인가? 로드밸렂서
데이터의 동기화는 어떻게 할 것인가? DB를 분산시켰을 때 한족에 저장된 갱신 내용을 다른 한쪽 DB가 알지 못한다면 애플리케이션 비정상 사태가 발생
네트워크 통신의 지연시간을 어떻게 생각해볼 수 있을까? 작은 데이터라도 지연시간이 발생한다. 통신의 오버헤드를 최소한으로 줄여가면서 애플리케이션을 구성해갈 필요가 있다.


##### 다중성 확보

서비스가 대규모화되면 될수록 시스템 정지의 사회적 충격도 늘어나므로 더욱 더 다중성 확보가 필요해진다.
웹 서비스는 언제 어떠한 경우라도 고장에 대해 견고해야 한다.

##### 효율적 운용 필요

##### 개발자 수, 개발방법의 변화

프로그래밍 언어를 통일, 라이브러리나 프레임워크를 통일, 코딩 규약을 표준화가 필요
개발자 개개인과 팀에서 표준화 규칙이 지켜지고 있는지, 기술자 간 능력 차이에 따라 효율이 나쁜 부분은 생기지 않는지, 교육은 어떻게 할 것인지 팀 매니지먼트가 필요하다.

#### 대규모 데이터량에 대한 대처

데이터는 디스크 -> 메모리 -> 캐시 메모리 -> CPU와 같이 몇 단계를 경유해서 처리되어 간다.
메모리나 캐시 메모리와 비교하면 10^6 ~ 10^9배나 되는 속도차가 나게 된다.
이 속도차를 흡수하기 위해 OS는 이런저런 방법을 사용하게 되는데, 예를 들면 디스크로부터 읽어들인 데이터를 메모리에 캐싱해둠으로써 전반적으로 디바이스간ㄷ 속도차가
체감속도에 영향을 주지 않도록 하고 있다.
하지만 데이터량이 많아지면 처음부터 캐시 미스가 발생하게 되고, 이는 저속의 디스크 I/O를 발생시키게 된다.

어떻게 하면 데이터를 적게 가져갈 수 있을까, 여러 서버로 분산시킬 수 있을까, 필요한 데이터를 최소한의 횟수로 읽어들일 수 있을지 등이 과제가 된다.


### 강의 2 계속 성장하는 서비스와 대규모화의 벽

#### 웹 서비스의 어려움

소규모였던 서비스가 성장함에 따라 그 규모가 확대해간다.
라우터는 Linux 박스로 저가에 구축, HTTP 요청 분산은 아피치의 mod_rewrite로 대용, DB 분산은 MySQL의 레플리케이션을 이용

#### 데이터 센터로의 이전, 시스템 쇄신
사전에 기존 시스템의 부하상황을 정리, 병목 지점을 측정, 판정하고 I/O 부하가 높은 서버는 메모리를 중요시하고 CPU 부하가 높은 서버는 CPU를 중요시하는 형태로 서버 용도에 맞게 최적의 구성을 갖는 하드웨어를 준비
다중화의 경우 로드밸런서 + 가동감시 기능을 하는 오픈소스 LVS + keepalived를 도입
서버 교체는 서서히 OS 가상화도 진행하여 서버 가동률을 높임과 동시에 유지 보수성을 높임

독자적 서버 정보관리 시스템도 개발, 
애플리케이션의 각종 로직, DB 스키마 재검토 비효율 개선

### 강의 3 서비스 개발의 현장

#### 하테나의 기술팀 체제
서비스 개발부 : 하테나의 각종 서비스 구현을 담당하는 팀, 매일 애플리케이션 측면의 개선을 담당
인프라부 : 서버/인프라 시스템의 운용을 담당하는 팀, 서버 준비, 데이터 센터 운용, 부하 분산 등을 담당

서비스 개발부에서도 담당하고 있는 서비스의 성능을 트래킹하고, 주요한 페이지가 어느 정도의 응답시간에 응답하고 있는지 정량화해 매일 그것을 지표로 한계값을 밑돌지 않도록 목표를 설정해 개선한다.

#### 하테나에서의 커뮤니케이션 방법

하테나 위키, IRC, 서버 관리툴

#### 실제 서비스 개발

매일 미팅 > 담당자 정하고 태스크 구현 > 구현 + 테스트 프로그램 최대한 작성 > 커밋 > 코드 리뷰 (코딩 규약, 과부하 찾기) > 머지 개발 확인 운영 배포

- 페어 프로그래밍도 함, 전체적으로 애자일 개발 스타일

#### 개발에 사용하는 툴
##### 프로그래밍 언어
전체적으로는 Perl
검색 엔진 등 메모리 요건이 엄격하거나 속도가 요구되는 곳에는 일부 C/C++로 구현
웹은 JS

##### 주요 미들웨어
Linux, Apache, MySQL, memcached

##### 웹 애플리케이션 프레임워크
Ridge Perl 프레임워크
O/R 매퍼 

##### 주위 머신의 OS 및 에디터
에디터 자유, Linux 구동해서 개발, 코딩 규약은 지킨다.

##### 버전 관리는 git BTS(Bug tracking system)은 직접 만든 아시카
##### 개발 툴에 관해서

## 2. 대규모 데이터 처리 입문
(메모리와 디스크, 웹 애플리케이션과 부하)

### 대규모 데이터 특유의 환경 알기

### 강의 4 하테나 북마크의 데이터 규모

#### 하테나 북마크를 예로 본 대규모 데이터
select * from relword -> 3억 5천만건이 조회됨

#### 하테나 북마크의 데이터 규모
entry - 3GB
bookmark - 5.5GB
tag - 4.8GB
HTML 압축 - 200GB
relword - 10GB

구글, 야후는 (테라, 페타바이트)
#### 대뮤모 데이터로의 쿼리
select url from entry use index(hoge) where eid = 9615899; 200초 기다려도 결과가 출력되지 않음

### 강의 5 대규모 데이터 처리의 어려운 점(메모리와 디스크)

#### 대규모 데이터는 어떤 점이 어려운가? - 메모리 내에서 계산할 수 없음

> 대규모 데이터의 어려움은 메모리 내에서 계산할 수 없다는 점
- 메모리 내에서 계산할 수 없게 되면 디스크에 있는 데이터를 검색할 필요가 있다.
- 하지만 디스크는 느리므로 (I/O)에 시간이 걸린다.
- 어떻게 대처할 것인가 연구 대상

#### 메모리와 디스크의 속도차
메모리는 10^5 ~ 10^6배 이상 고속

#### 디스크는 왜 늦을까?
메모리는 전기적인 부품이므로 물리적 구조는 탐색속도와 그다지 관계 없음 - 마이크로초 단위로 포인터를 이동시킬 수 있음
디스크는 메모리와 달리 회전 등의 물리적인 동작을 수반하고 있음

##### 탐색속도에 영향을 주는 다양한 요인
디스크에서는 헤드의 이동과 원반의 회전이라는 두 가지 물리적인 이동이 필요함 (오버헤드가 있음)

#### OS 레벨에서의 연구
디스크는 느리지만 OS는 이것을 어느 정도 커버하는 작용을 한다.
비슷한 데이터를 비슷한 곳에 두어 1번의 디스크 회전으로 읽는 데이터 수를 많게 한다, 디스크의 회전횟수를 최소화한다.

#### 전송속도, 버스의 속도차
전송속도에서 100배 이상 차이가 난다.
메모리 : 7.5GB/s
디스크 : 58MB/s

- sudo /sbin/hdparm -t /dev/sda

(SSD가 나와 물리적인 회전이 아니라 탐색이 빠르지만 버스속도가 병목이 되거나 함)

Linux 단일 호스트의 부하
추측하지 말라, 계측하라(단일 호스트의 성능 끌어내기) > 병목 규명작업의 기본적인 흐름 (Load Average확인, CPU, I/O 병목 원인 조사)
OS 튜닝

### 강의 6 규모조정의 요소

