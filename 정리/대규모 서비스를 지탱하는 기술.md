# 대규모 서비스를 지탱하는 기술

## 챕터 1 대규모 웹 서비스 개발 오리엔테이션

### 강의 0 이 책의 근간

사용자가 이용하고 있는 대규모 서비스에 변경을 가할 때 규모를 고려하지 않고 어중간하게 구현해서 적용하다 보면, 어이없게도 아주 간단히 시스템 정지를 초래할 수 있음

- 대규모 웹 서비스 개발이란?
- 대규모 데이터를 다룰 때의 과제, 다루기 위한 기본적인 사고방식과 요령 (OS의 캐시 기능, 대규모 데이터를 전제로 한 DB운용)
- 알고리즘과 데이터 구조 선택의 중요성, (대규모 데이터)
- RDBMS로 모두 다룰 수 없는 규모의 데이터 처리방법 (검색 엔진)
- 대규모 서비스가 될 것을 전제로 한 서버/인프라 시스템의 예와 개념

### 강의 1 대규모 서비스와 소규모 서비스

- 등록 사용자는 100만 명 이상, 1500만명 UU
- 수십 억 액세스/월
- 피크 시 회선 트래픽 430Mbps
- 하드웨어 서버 500대 이상


#### 소규모 서비스와 대규모 서비스의 차이

##### 확장성 확보, 부하분산 필요

스케일 아웃 - 서버를 횡으로 전개, 즉 서버의 역할을 분담하거나 대수를 늘림으로써 시스템의 전체적인 처리능력을 높여서 부하를 분산하는 방법
스케일 업 - 하드웨어의 성능을 높여 처리능력을 끌어올리는 방법

사용자로부터의 요청을 어떻게 분배할 것인가? 로드밸렂서
데이터의 동기화는 어떻게 할 것인가? DB를 분산시켰을 때 한족에 저장된 갱신 내용을 다른 한쪽 DB가 알지 못한다면 애플리케이션 비정상 사태가 발생
네트워크 통신의 지연시간을 어떻게 생각해볼 수 있을까? 작은 데이터라도 지연시간이 발생한다. 통신의 오버헤드를 최소한으로 줄여가면서 애플리케이션을 구성해갈 필요가 있다.


##### 다중성 확보

서비스가 대규모화되면 될수록 시스템 정지의 사회적 충격도 늘어나므로 더욱 더 다중성 확보가 필요해진다.
웹 서비스는 언제 어떠한 경우라도 고장에 대해 견고해야 한다.

##### 효율적 운용 필요

##### 개발자 수, 개발방법의 변화

프로그래밍 언어를 통일, 라이브러리나 프레임워크를 통일, 코딩 규약을 표준화가 필요
개발자 개개인과 팀에서 표준화 규칙이 지켜지고 있는지, 기술자 간 능력 차이에 따라 효율이 나쁜 부분은 생기지 않는지, 교육은 어떻게 할 것인지 팀 매니지먼트가 필요하다.

#### 대규모 데이터량에 대한 대처

데이터는 디스크 -> 메모리 -> 캐시 메모리 -> CPU와 같이 몇 단계를 경유해서 처리되어 간다.
메모리나 캐시 메모리와 비교하면 10^6 ~ 10^9배나 되는 속도차가 나게 된다.
이 속도차를 흡수하기 위해 OS는 이런저런 방법을 사용하게 되는데, 예를 들면 디스크로부터 읽어들인 데이터를 메모리에 캐싱해둠으로써 전반적으로 디바이스간ㄷ 속도차가
체감속도에 영향을 주지 않도록 하고 있다.
하지만 데이터량이 많아지면 처음부터 캐시 미스가 발생하게 되고, 이는 저속의 디스크 I/O를 발생시키게 된다.

어떻게 하면 데이터를 적게 가져갈 수 있을까, 여러 서버로 분산시킬 수 있을까, 필요한 데이터를 최소한의 횟수로 읽어들일 수 있을지 등이 과제가 된다.

### 강의 2 계속 성장하는 서비스와 대규모화의 벽

#### 웹 서비스의 어려움

소규모였던 서비스가 성장함에 따라 그 규모가 확대해간다.
라우터는 Linux 박스로 저가에 구축, HTTP 요청 분산은 아피치의 mod_rewrite로 대용, DB 분산은 MySQL의 레플리케이션을 이용

#### 데이터 센터로의 이전, 시스템 쇄신
사전에 기존 시스템의 부하상황을 정리, 병목 지점을 측정, 판정하고 I/O 부하가 높은 서버는 메모리를 중요시하고 CPU 부하가 높은 서버는 CPU를 중요시하는 형태로 서버 용도에 맞게 최적의 구성을 갖는 하드웨어를 준비
다중화의 경우 로드밸런서 + 가동감시 기능을 하는 오픈소스 LVS + keepalived를 도입
서버 교체는 서서히 OS 가상화도 진행하여 서버 가동률을 높임과 동시에 유지 보수성을 높임

독자적 서버 정보관리 시스템도 개발, 
애플리케이션의 각종 로직, DB 스키마 재검토 비효율 개선

### 강의 3 서비스 개발의 현장

#### 하테나의 기술팀 체제
서비스 개발부 : 하테나의 각종 서비스 구현을 담당하는 팀, 매일 애플리케이션 측면의 개선을 담당
인프라부 : 서버/인프라 시스템의 운용을 담당하는 팀, 서버 준비, 데이터 센터 운용, 부하 분산 등을 담당

서비스 개발부에서도 담당하고 있는 서비스의 성능을 트래킹하고, 주요한 페이지가 어느 정도의 응답시간에 응답하고 있는지 정량화해 매일 그것을 지표로 한계값을 밑돌지 않도록 목표를 설정해 개선한다.

#### 하테나에서의 커뮤니케이션 방법

하테나 위키, IRC, 서버 관리툴

#### 실제 서비스 개발

매일 미팅 > 담당자 정하고 태스크 구현 > 구현 + 테스트 프로그램 최대한 작성 > 커밋 > 코드 리뷰 (코딩 규약, 과부하 찾기) > 머지 개발 확인 운영 배포

- 페어 프로그래밍도 함, 전체적으로 애자일 개발 스타일

#### 개발에 사용하는 툴
##### 프로그래밍 언어
전체적으로는 Perl
검색 엔진 등 메모리 요건이 엄격하거나 속도가 요구되는 곳에는 일부 C/C++로 구현
웹은 JS

##### 주요 미들웨어
Linux, Apache, MySQL, memcached

##### 웹 애플리케이션 프레임워크
Ridge Perl 프레임워크
O/R 매퍼 

##### 주위 머신의 OS 및 에디터
에디터 자유, Linux 구동해서 개발, 코딩 규약은 지킨다.

##### 버전 관리는 git BTS(Bug tracking system)은 직접 만든 아시카
##### 개발 툴에 관해서

## 2. 대규모 데이터 처리 입문
(메모리와 디스크, 웹 애플리케이션과 부하)

### 대규모 데이터 특유의 환경 알기

### 강의 4 하테나 북마크의 데이터 규모

#### 하테나 북마크를 예로 본 대규모 데이터
select * from relword -> 3억 5천만건이 조회됨

#### 하테나 북마크의 데이터 규모
entry - 3GB
bookmark - 5.5GB
tag - 4.8GB
HTML 압축 - 200GB
relword - 10GB

구글, 야후는 (테라, 페타바이트)
#### 대뮤모 데이터로의 쿼리
select url from entry use index(hoge) where eid = 9615899; 200초 기다려도 결과가 출력되지 않음

### 강의 5 대규모 데이터 처리의 어려운 점(메모리와 디스크)

#### 대규모 데이터는 어떤 점이 어려운가? - 메모리 내에서 계산할 수 없음

> 대규모 데이터의 어려움은 메모리 내에서 계산할 수 없다는 점
- 메모리 내에서 계산할 수 없게 되면 디스크에 있는 데이터를 검색할 필요가 있다.
- 하지만 디스크는 느리므로 (I/O)에 시간이 걸린다.
- 어떻게 대처할 것인가 연구 대상

#### 메모리와 디스크의 속도차
메모리는 10^5 ~ 10^6배 이상 고속

#### 디스크는 왜 늦을까?
메모리는 전기적인 부품이므로 물리적 구조는 탐색속도와 그다지 관계 없음 - 마이크로초 단위로 포인터를 이동시킬 수 있음
디스크는 메모리와 달리 회전 등의 물리적인 동작을 수반하고 있음

##### 탐색속도에 영향을 주는 다양한 요인
디스크에서는 헤드의 이동과 원반의 회전이라는 두 가지 물리적인 이동이 필요함 (오버헤드가 있음)

#### OS 레벨에서의 연구
디스크는 느리지만 OS는 이것을 어느 정도 커버하는 작용을 한다.
비슷한 데이터를 비슷한 곳에 두어 1번의 디스크 회전으로 읽는 데이터 수를 많게 한다, 디스크의 회전횟수를 최소화한다.

#### 전송속도, 버스의 속도차
전송속도에서 100배 이상 차이가 난다.
메모리 : 7.5GB/s
디스크 : 58MB/s

- sudo /sbin/hdparm -t /dev/sda

(SSD가 나와 물리적인 회전이 아니라 탐색이 빠르지만 버스속도가 병목이 되거나 함)

Linux 단일 호스트의 부하
추측하지 말라, 계측하라(단일 호스트의 성능 끌어내기) > 병목 규명작업의 기본적인 흐름 (Load Average확인, CPU, I/O 병목 원인 조사)
OS 튜닝

## 챕터 2 계속 성장하는 서비스와 대규모화의 벽

### 강의 6 규모조정의 요소

#### 규모조정, 확장성
스케일 업보다는 스케일 아웃이 비용이 저렴하고 시스템 구성에 유연성이 있다.

#### 규모조정의 요소
스케일 아웃은 하드웨어를 나열해서 성능을 높이는, 즉 하드웨어를 횡으로 전개해서 확장성을 확보해가게 된다. 이떄 CPU 부하의 확장성을 확보하기는 쉽다.
한편 DB 서버 측면에서는 I/O qngkrk rjfflsek.

#### 웹 애플리케이션과 부하의 관계

웹 애플리케이션의 3단 구조는 프록시 > AP 서버 > DB 가 있다.
DB 지난 데이터와 동기화 문제 DB에 쓰인 내용을 어떻게 복사 DB에 옮길 것인가 문제가 있음

#### DB 확장성 확보의 어려움

CPU 부하의 규모조정은 간단
- 같은 구성의 서버를 늘리고 로드밸런서로 분산
- 웹, AP 서버, 크롤러

I/O 부하의 규모조정은 어렵다.
- DB
- 대규모 데이터

> 멀티태스킹 OS와 부하
> top의 출력 내용에는 Load Average라는 수치가 포함되어 있음
> load average는 1분, 5분, 15분 단위 시간당 대기된 태스크의 수를 나타냄
>
> Average가 보고하는 부하의 정체
> 하드웨어는 일정 주기로 CPU로 인터럽트 신호를 보냄 Load Average 값이 계산
>
> 처리를 실행하려고 해도 실행할 수 없어서 대기하고 있는 프로세스의 수
> CPU의 실행권한이 부여되기를 기다리고 있는 프로세스, 디스크 I/O가 완료하기를 기다리고 있는 프로세스

### 강의 7 대규모 데이터를 다루기 위한 기초지식

#### 프로그래머를 위한 대규모 데이터 기초
대규모 데이터는 메모리에서 처리하기 어렵고 디스크는 느림

#### 대규모 데이터를 다루는 세 가지 급소 (프로그램을 작성할 때의 요령)

- 메모리에서 처리를 마쳐야 하는 이유는 디스크 seek 횟수가 확장성, 성능에 영향을 주기 때문 (디스크 횟수 최소화, 국소성을 활용한 분산)
- 데이터량 증가에 강한 알고리즘을 사용한다. (Log order, 이분검색)
- 데이터 압축이나 검색기술과 같은 테크닉을 사용한다.
(데이터량을 줄이면 seek 횟수 줄고, 메모리 캐싱이 쉬워짐)

#### 대규모 데이터를 다루기 전 3대 전제지식

- OS 캐시
- 분산 고려 RDBMS
- 대규모 환경에서 알고리즘과 데이터 구조를 사용한다는 것

하테나는 AP 서버 10대, DB 서버 25대

AP 서버는 늘리면 늘릴수록 점점 빨리지지만 DB 서버는 늘리더라도 의미가 없는 경우가 자주 있음

## 챕터 3 OS 캐시와 분산 (대규모 데이터를 효율적으로 처리하는 원리)

### 대규모 데이터를 다룰 때의 포인트 - I/O 대책에 대한 기반은 OS에 있다.
OS 캐시로 제대로 처리할 수 없게 되었을 때 분산에 대해 고려해보게 된다. 

OS 캐시와 분산
- OS 캐시
- 캐시를 전제로 한 I/O 부하 줄이는 방법
- 캐시를 고려한 국소성을 살리는 분산

### 강의 8 OS의 캐시 구조

#### OS의 캐시 구조를 알고 애플리케이션 작성하기 - 페이지 캐시
메모리, 디스크, OS 캐시 구조
- 디스크와 메모리 간 속도차를 10^5 ~ 10^6 배 이상
- 메모리를 이용해서 디스크 액세스를 줄이고자 한다. -> OS는 캐시 구조를 갖추고 있다.

##### Linux(x86)의 페이징 구조를 예로
선형 어드레스
    |
    V
페이징 구조
    |
    V
물리 어드레스
- 가상 메모리 구조의 기반
- 논리적인 선형 어드레스를 물리적인 물리 어드레스로 변환

> 스왑은 가상 메모리를 응용한 기능 중 하나로 물리 메모리가 부족할 때 2차 기억장치(주로 디스크)를 메모리로 간주해서 외형상의 메모리 부족을 해소하는 원리이다.

##### 가상 메모리 구조
가상 메모리 구조가 존재하는 가장 큰 이유는 물리적인 하드웨어를 OS에서 추상화하기 위해서다.
- 프로세스는 메모리의 어느 부분을 사용하고 있는지 알고 싶어하지 않는다.
- 0x000과 같이 반드시 메모리의 특정 번지부터 시작한다고 정해져 있는 편이 프로세스에게는 다루기 쉽다.

유닉스의 공유 라이브러리는 프로세스 내의 지정된 주소로 할당되도록 되어 있다. 프로세스 내의 지정된 주소로 할당되도록 되어 있다.
(포인트는 OS라는 것은 메모리를 직접 프로세스로 넘기는 것이 아니라 일단 커널 내에서 메모리를 추상화한다는 것이다.)

메모리를 확보할때도 4KB 정도를 블록으로 확보해서 프로세스에 넘김

가상 메모리
- 프로세스에서 메모리를 다루기 쉽게하는 이점을 제공
- OS가 커널 내에서 메모리를 추상화하고 있다.
- 페이지: OS가 물리 메모리를 확보/관리하는 단위

#### Linux의 페이지 캐시 원리
OS는 확보한 페이지를 메모리상에 계속 확보해두는 기능을 갖고 있다.

이번 디스크 읽기는 끝나고 데이터는 전부 처리했으므로 더 이상 불필요하게 됐어도 해제하지 않고 남겨두는 것 -> 페이지 캐시
커널이 한 번 할당한 메모리를 해제하지 않고 계속 남겨두는 것이 페이지 캐시의 기본이다.

##### 페이지 캐시의 친숙한 효과
Linux에서는 디스크에 데이터를 읽으러 가면 꼭 한 번은 메모리로 가서 데이터가 반드시 캐싱된다. 현대의 OS는 대체로 페이지 캐시와 비슷한 구조를 갖추고 있다.
Windows 머신도 부팅 직후에는 캐시가 없으므로 디스크 I/O가 발생하기 쉬워 다소 버벅거리는 것처럼 느껴질 수 있다.

Linux의 페이지 캐시
- 디스크의 내용을 일단 메모리에 읽어들인다. -> 페이지가 작성된다.
- 작성된 페이지는 파기되지 않고 남긴다. -> 페이지 캐시
- 예외의 경우를 제외하고 모든 I/O에 투과적으로 작용한다. -> 디스크의 캐시를 담당하는 곳(VFS)

#### VFS
디스크의 캐시는 페이지 캐시에 의해 제공되지만, 실제 이 디스크를 조작하는 디바이스 드라이버와 OS 사이에는 파일시스템이 끼어 있다.
Linux에는 ext3, ext2, ext4, xfs 등 몇몇 파일시스템이 있는데 그 하위에 디바이스 드라이버가 있으며, 이 디바이스 드라이버가 실제로 하드디스크 등을 조작한다.
vfs의 역할은 파일시스템 구현의 추상화와 성능에 관련된 페이지 캐시 부분이다.

#### Linux는 페이지 단위로 디스크를 캐싱한다.
페이지 캐시인 이유는 OS는 읽어낸 블록 단위만으로 캐싱할 수 있는 범위가 정해진다.
여기서는 디스크상에 배치되어 있는 4KB 블록만을 캐싱하므로 특정 파일의 일부분만, 읽어낸 부분만을 캐싱할 수 있다.

페이지 = 가상 메모리의 최소단위

##### LRU
가장 오래된 것을 파기하고 가장 새로운 것을 남겨놓는 형태로 되어 있으므로 최근에 읽은 부분이 캐시에 남고 과거에 읽은 부분이 파기되어 간다.

##### 어떻게 캐싱할까?
어떤 파일의 어느 위치를 이라는 쌍으로 캐시의 키를 관리할 수 있다.
OS 내부에서 사용되고 있는 데이터 구조는 Radix Tree라고 하며, 파일이 아무리 커지더라도 캐시 탐색속도가 떨어지지 않도록 개발된 데이터 구조다.

#### 메모리가 비어 있으면 캐싱 - sar로 확인
Linux는 메모리가 비어 있으면 전부 캐싱
- 제한 없음 -> sar -r 로 확인

#### 메모리를 늘려서 I/O 부하 줄이기
메모리를 늘리면 캐시에 사용할 수 있는 용량이 늘어나고, 캐시에 사용할 수 있는 용량이 늘어나면 보다 많은 데이터를 캐싱할 수 있고, 많이 캐싱되면 디스크를 읽는 횟수가 줄어든다.

#### 페이지 캐시는 투과적으로 작용한다.

### 강의 9 I/O 부하를 줄이는 방법



