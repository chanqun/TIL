# 대규모 서비스를 지탱하는 기술

## 챕터 1 대규모 웹 서비스 개발 오리엔테이션

### 강의 0 이 책의 근간

사용자가 이용하고 있는 대규모 서비스에 변경을 가할 때 규모를 고려하지 않고 어중간하게 구현해서 적용하다 보면, 어이없게도 아주 간단히 시스템 정지를 초래할 수 있음

- 대규모 웹 서비스 개발이란?
- 대규모 데이터를 다룰 때의 과제, 다루기 위한 기본적인 사고방식과 요령 (OS의 캐시 기능, 대규모 데이터를 전제로 한 DB운용)
- 알고리즘과 데이터 구조 선택의 중요성, (대규모 데이터)
- RDBMS로 모두 다룰 수 없는 규모의 데이터 처리방법 (검색 엔진)
- 대규모 서비스가 될 것을 전제로 한 서버/인프라 시스템의 예와 개념

### 강의 1 대규모 서비스와 소규모 서비스

- 등록 사용자는 100만 명 이상, 1500만명 UU
- 수십 억 액세스/월
- 피크 시 회선 트래픽 430Mbps
- 하드웨어 서버 500대 이상


#### 소규모 서비스와 대규모 서비스의 차이

##### 확장성 확보, 부하분산 필요

스케일 아웃 - 서버를 횡으로 전개, 즉 서버의 역할을 분담하거나 대수를 늘림으로써 시스템의 전체적인 처리능력을 높여서 부하를 분산하는 방법
스케일 업 - 하드웨어의 성능을 높여 처리능력을 끌어올리는 방법

사용자로부터의 요청을 어떻게 분배할 것인가? 로드밸렂서
데이터의 동기화는 어떻게 할 것인가? DB를 분산시켰을 때 한족에 저장된 갱신 내용을 다른 한쪽 DB가 알지 못한다면 애플리케이션 비정상 사태가 발생
네트워크 통신의 지연시간을 어떻게 생각해볼 수 있을까? 작은 데이터라도 지연시간이 발생한다. 통신의 오버헤드를 최소한으로 줄여가면서 애플리케이션을 구성해갈 필요가 있다.


##### 다중성 확보

서비스가 대규모화되면 될수록 시스템 정지의 사회적 충격도 늘어나므로 더욱 더 다중성 확보가 필요해진다.
웹 서비스는 언제 어떠한 경우라도 고장에 대해 견고해야 한다.

##### 효율적 운용 필요

##### 개발자 수, 개발방법의 변화

프로그래밍 언어를 통일, 라이브러리나 프레임워크를 통일, 코딩 규약을 표준화가 필요
개발자 개개인과 팀에서 표준화 규칙이 지켜지고 있는지, 기술자 간 능력 차이에 따라 효율이 나쁜 부분은 생기지 않는지, 교육은 어떻게 할 것인지 팀 매니지먼트가 필요하다.

#### 대규모 데이터량에 대한 대처

데이터는 디스크 -> 메모리 -> 캐시 메모리 -> CPU와 같이 몇 단계를 경유해서 처리되어 간다.
메모리나 캐시 메모리와 비교하면 10^6 ~ 10^9배나 되는 속도차가 나게 된다.
이 속도차를 흡수하기 위해 OS는 이런저런 방법을 사용하게 되는데, 예를 들면 디스크로부터 읽어들인 데이터를 메모리에 캐싱해둠으로써 전반적으로 디바이스간ㄷ 속도차가
체감속도에 영향을 주지 않도록 하고 있다.
하지만 데이터량이 많아지면 처음부터 캐시 미스가 발생하게 되고, 이는 저속의 디스크 I/O를 발생시키게 된다.

어떻게 하면 데이터를 적게 가져갈 수 있을까, 여러 서버로 분산시킬 수 있을까, 필요한 데이터를 최소한의 횟수로 읽어들일 수 있을지 등이 과제가 된다.

### 강의 2 계속 성장하는 서비스와 대규모화의 벽

#### 웹 서비스의 어려움

소규모였던 서비스가 성장함에 따라 그 규모가 확대해간다.
라우터는 Linux 박스로 저가에 구축, HTTP 요청 분산은 아피치의 mod_rewrite로 대용, DB 분산은 MySQL의 레플리케이션을 이용

#### 데이터 센터로의 이전, 시스템 쇄신
사전에 기존 시스템의 부하상황을 정리, 병목 지점을 측정, 판정하고 I/O 부하가 높은 서버는 메모리를 중요시하고 CPU 부하가 높은 서버는 CPU를 중요시하는 형태로 서버 용도에 맞게 최적의 구성을 갖는 하드웨어를 준비
다중화의 경우 로드밸런서 + 가동감시 기능을 하는 오픈소스 LVS + keepalived를 도입
서버 교체는 서서히 OS 가상화도 진행하여 서버 가동률을 높임과 동시에 유지 보수성을 높임

독자적 서버 정보관리 시스템도 개발, 
애플리케이션의 각종 로직, DB 스키마 재검토 비효율 개선

### 강의 3 서비스 개발의 현장

#### 하테나의 기술팀 체제
서비스 개발부 : 하테나의 각종 서비스 구현을 담당하는 팀, 매일 애플리케이션 측면의 개선을 담당
인프라부 : 서버/인프라 시스템의 운용을 담당하는 팀, 서버 준비, 데이터 센터 운용, 부하 분산 등을 담당

서비스 개발부에서도 담당하고 있는 서비스의 성능을 트래킹하고, 주요한 페이지가 어느 정도의 응답시간에 응답하고 있는지 정량화해 매일 그것을 지표로 한계값을 밑돌지 않도록 목표를 설정해 개선한다.

#### 하테나에서의 커뮤니케이션 방법

하테나 위키, IRC, 서버 관리툴

#### 실제 서비스 개발

매일 미팅 > 담당자 정하고 태스크 구현 > 구현 + 테스트 프로그램 최대한 작성 > 커밋 > 코드 리뷰 (코딩 규약, 과부하 찾기) > 머지 개발 확인 운영 배포

- 페어 프로그래밍도 함, 전체적으로 애자일 개발 스타일

#### 개발에 사용하는 툴
##### 프로그래밍 언어
전체적으로는 Perl
검색 엔진 등 메모리 요건이 엄격하거나 속도가 요구되는 곳에는 일부 C/C++로 구현
웹은 JS

##### 주요 미들웨어
Linux, Apache, MySQL, memcached

##### 웹 애플리케이션 프레임워크
Ridge Perl 프레임워크
O/R 매퍼 

##### 주위 머신의 OS 및 에디터
에디터 자유, Linux 구동해서 개발, 코딩 규약은 지킨다.

##### 버전 관리는 git BTS(Bug tracking system)은 직접 만든 아시카
##### 개발 툴에 관해서

## 2. 대규모 데이터 처리 입문
(메모리와 디스크, 웹 애플리케이션과 부하)

### 대규모 데이터 특유의 환경 알기

### 강의 4 하테나 북마크의 데이터 규모

#### 하테나 북마크를 예로 본 대규모 데이터
select * from relword -> 3억 5천만건이 조회됨

#### 하테나 북마크의 데이터 규모
entry - 3GB
bookmark - 5.5GB
tag - 4.8GB
HTML 압축 - 200GB
relword - 10GB

구글, 야후는 (테라, 페타바이트)
#### 대뮤모 데이터로의 쿼리
select url from entry use index(hoge) where eid = 9615899; 200초 기다려도 결과가 출력되지 않음

### 강의 5 대규모 데이터 처리의 어려운 점(메모리와 디스크)

#### 대규모 데이터는 어떤 점이 어려운가? - 메모리 내에서 계산할 수 없음

> 대규모 데이터의 어려움은 메모리 내에서 계산할 수 없다는 점
- 메모리 내에서 계산할 수 없게 되면 디스크에 있는 데이터를 검색할 필요가 있다.
- 하지만 디스크는 느리므로 (I/O)에 시간이 걸린다.
- 어떻게 대처할 것인가 연구 대상

#### 메모리와 디스크의 속도차
메모리는 10^5 ~ 10^6배 이상 고속

#### 디스크는 왜 늦을까?
메모리는 전기적인 부품이므로 물리적 구조는 탐색속도와 그다지 관계 없음 - 마이크로초 단위로 포인터를 이동시킬 수 있음
디스크는 메모리와 달리 회전 등의 물리적인 동작을 수반하고 있음

##### 탐색속도에 영향을 주는 다양한 요인
디스크에서는 헤드의 이동과 원반의 회전이라는 두 가지 물리적인 이동이 필요함 (오버헤드가 있음)

#### OS 레벨에서의 연구
디스크는 느리지만 OS는 이것을 어느 정도 커버하는 작용을 한다.
비슷한 데이터를 비슷한 곳에 두어 1번의 디스크 회전으로 읽는 데이터 수를 많게 한다, 디스크의 회전횟수를 최소화한다.

#### 전송속도, 버스의 속도차
전송속도에서 100배 이상 차이가 난다.
메모리 : 7.5GB/s
디스크 : 58MB/s

- sudo /sbin/hdparm -t /dev/sda

(SSD가 나와 물리적인 회전이 아니라 탐색이 빠르지만 버스속도가 병목이 되거나 함)

Linux 단일 호스트의 부하
추측하지 말라, 계측하라(단일 호스트의 성능 끌어내기) > 병목 규명작업의 기본적인 흐름 (Load Average확인, CPU, I/O 병목 원인 조사)
OS 튜닝

## 챕터 2 계속 성장하는 서비스와 대규모화의 벽

### 강의 6 규모조정의 요소

#### 규모조정, 확장성
스케일 업보다는 스케일 아웃이 비용이 저렴하고 시스템 구성에 유연성이 있다.

#### 규모조정의 요소
스케일 아웃은 하드웨어를 나열해서 성능을 높이는, 즉 하드웨어를 횡으로 전개해서 확장성을 확보해가게 된다. 이떄 CPU 부하의 확장성을 확보하기는 쉽다.
한편 DB 서버 측면에서는 I/O qngkrk rjfflsek.

#### 웹 애플리케이션과 부하의 관계

웹 애플리케이션의 3단 구조는 프록시 > AP 서버 > DB 가 있다.
DB 지난 데이터와 동기화 문제 DB에 쓰인 내용을 어떻게 복사 DB에 옮길 것인가 문제가 있음

#### DB 확장성 확보의 어려움

CPU 부하의 규모조정은 간단
- 같은 구성의 서버를 늘리고 로드밸런서로 분산
- 웹, AP 서버, 크롤러

I/O 부하의 규모조정은 어렵다.
- DB
- 대규모 데이터

> 멀티태스킹 OS와 부하
> top의 출력 내용에는 Load Average라는 수치가 포함되어 있음
> load average는 1분, 5분, 15분 단위 시간당 대기된 태스크의 수를 나타냄
>
> Average가 보고하는 부하의 정체
> 하드웨어는 일정 주기로 CPU로 인터럽트 신호를 보냄 Load Average 값이 계산
>
> 처리를 실행하려고 해도 실행할 수 없어서 대기하고 있는 프로세스의 수
> CPU의 실행권한이 부여되기를 기다리고 있는 프로세스, 디스크 I/O가 완료하기를 기다리고 있는 프로세스

### 강의 7 대규모 데이터를 다루기 위한 기초지식

#### 프로그래머를 위한 대규모 데이터 기초
대규모 데이터는 메모리에서 처리하기 어렵고 디스크는 느림

#### 대규모 데이터를 다루는 세 가지 급소 (프로그램을 작성할 때의 요령)

- 메모리에서 처리를 마쳐야 하는 이유는 디스크 seek 횟수가 확장성, 성능에 영향을 주기 때문 (디스크 횟수 최소화, 국소성을 활용한 분산)
- 데이터량 증가에 강한 알고리즘을 사용한다. (Log order, 이분검색)
- 데이터 압축이나 검색기술과 같은 테크닉을 사용한다.
(데이터량을 줄이면 seek 횟수 줄고, 메모리 캐싱이 쉬워짐)

#### 대규모 데이터를 다루기 전 3대 전제지식

- OS 캐시
- 분산 고려 RDBMS
- 대규모 환경에서 알고리즘과 데이터 구조를 사용한다는 것

하테나는 AP 서버 10대, DB 서버 25대

AP 서버는 늘리면 늘릴수록 점점 빨리지지만 DB 서버는 늘리더라도 의미가 없는 경우가 자주 있음

## 챕터 3 OS 캐시와 분산 (대규모 데이터를 효율적으로 처리하는 원리)

### 대규모 데이터를 다룰 때의 포인트 - I/O 대책에 대한 기반은 OS에 있다.
OS 캐시로 제대로 처리할 수 없게 되었을 때 분산에 대해 고려해보게 된다. 

OS 캐시와 분산
- OS 캐시
- 캐시를 전제로 한 I/O 부하 줄이는 방법
- 캐시를 고려한 국소성을 살리는 분산

### 강의 8 OS의 캐시 구조

#### OS의 캐시 구조를 알고 애플리케이션 작성하기 - 페이지 캐시
메모리, 디스크, OS 캐시 구조
- 디스크와 메모리 간 속도차를 10^5 ~ 10^6 배 이상
- 메모리를 이용해서 디스크 액세스를 줄이고자 한다. -> OS는 캐시 구조를 갖추고 있다.

##### Linux(x86)의 페이징 구조를 예로
선형 어드레스
    |
    V
페이징 구조
    |
    V
물리 어드레스
- 가상 메모리 구조의 기반
- 논리적인 선형 어드레스를 물리적인 물리 어드레스로 변환

> 스왑은 가상 메모리를 응용한 기능 중 하나로 물리 메모리가 부족할 때 2차 기억장치(주로 디스크)를 메모리로 간주해서 외형상의 메모리 부족을 해소하는 원리이다.

##### 가상 메모리 구조
가상 메모리 구조가 존재하는 가장 큰 이유는 물리적인 하드웨어를 OS에서 추상화하기 위해서다.
- 프로세스는 메모리의 어느 부분을 사용하고 있는지 알고 싶어하지 않는다.
- 0x000과 같이 반드시 메모리의 특정 번지부터 시작한다고 정해져 있는 편이 프로세스에게는 다루기 쉽다.

유닉스의 공유 라이브러리는 프로세스 내의 지정된 주소로 할당되도록 되어 있다. 프로세스 내의 지정된 주소로 할당되도록 되어 있다.
(포인트는 OS라는 것은 메모리를 직접 프로세스로 넘기는 것이 아니라 일단 커널 내에서 메모리를 추상화한다는 것이다.)

메모리를 확보할때도 4KB 정도를 블록으로 확보해서 프로세스에 넘김

가상 메모리
- 프로세스에서 메모리를 다루기 쉽게하는 이점을 제공
- OS가 커널 내에서 메모리를 추상화하고 있다.
- 페이지: OS가 물리 메모리를 확보/관리하는 단위

#### Linux의 페이지 캐시 원리
OS는 확보한 페이지를 메모리상에 계속 확보해두는 기능을 갖고 있다.

이번 디스크 읽기는 끝나고 데이터는 전부 처리했으므로 더 이상 불필요하게 됐어도 해제하지 않고 남겨두는 것 -> 페이지 캐시
커널이 한 번 할당한 메모리를 해제하지 않고 계속 남겨두는 것이 페이지 캐시의 기본이다.

##### 페이지 캐시의 친숙한 효과
Linux에서는 디스크에 데이터를 읽으러 가면 꼭 한 번은 메모리로 가서 데이터가 반드시 캐싱된다. 현대의 OS는 대체로 페이지 캐시와 비슷한 구조를 갖추고 있다.
Windows 머신도 부팅 직후에는 캐시가 없으므로 디스크 I/O가 발생하기 쉬워 다소 버벅거리는 것처럼 느껴질 수 있다.

Linux의 페이지 캐시
- 디스크의 내용을 일단 메모리에 읽어들인다. -> 페이지가 작성된다.
- 작성된 페이지는 파기되지 않고 남긴다. -> 페이지 캐시
- 예외의 경우를 제외하고 모든 I/O에 투과적으로 작용한다. -> 디스크의 캐시를 담당하는 곳(VFS)

#### VFS
디스크의 캐시는 페이지 캐시에 의해 제공되지만, 실제 이 디스크를 조작하는 디바이스 드라이버와 OS 사이에는 파일시스템이 끼어 있다.
Linux에는 ext3, ext2, ext4, xfs 등 몇몇 파일시스템이 있는데 그 하위에 디바이스 드라이버가 있으며, 이 디바이스 드라이버가 실제로 하드디스크 등을 조작한다.
vfs의 역할은 파일시스템 구현의 추상화와 성능에 관련된 페이지 캐시 부분이다.

#### Linux는 페이지 단위로 디스크를 캐싱한다.
페이지 캐시인 이유는 OS는 읽어낸 블록 단위만으로 캐싱할 수 있는 범위가 정해진다.
여기서는 디스크상에 배치되어 있는 4KB 블록만을 캐싱하므로 특정 파일의 일부분만, 읽어낸 부분만을 캐싱할 수 있다.

페이지 = 가상 메모리의 최소단위

##### LRU
가장 오래된 것을 파기하고 가장 새로운 것을 남겨놓는 형태로 되어 있으므로 최근에 읽은 부분이 캐시에 남고 과거에 읽은 부분이 파기되어 간다.

##### 어떻게 캐싱할까?
어떤 파일의 어느 위치를 이라는 쌍으로 캐시의 키를 관리할 수 있다.
OS 내부에서 사용되고 있는 데이터 구조는 Radix Tree라고 하며, 파일이 아무리 커지더라도 캐시 탐색속도가 떨어지지 않도록 개발된 데이터 구조다.

#### 메모리가 비어 있으면 캐싱 - sar로 확인
Linux는 메모리가 비어 있으면 전부 캐싱
- 제한 없음 -> sar -r 로 확인

#### 메모리를 늘려서 I/O 부하 줄이기
메모리를 늘리면 캐시에 사용할 수 있는 용량이 늘어나고, 캐시에 사용할 수 있는 용량이 늘어나면 보다 많은 데이터를 캐싱할 수 있고, 많이 캐싱되면 디스크를 읽는 횟수가 줄어든다.

#### 페이지 캐시는 투과적으로 작용한다.

### 강의 9 I/O 부하를 줄이는 방법

#### 캐시를 전제로 한 I/O 줄이는 방법
캐시에 의한 I/O 경감효과는 매우 크다. 

첫 번째 포인트 
포인트는 데이터 규모에 비해 물리 메모리가 크면 전부 캐싱할 수 있으므로 이 점을 생각할 것 다루고자 하는 데이터의 크기에 주목한다.
또한 대규모 데이터 처리에는 데이터 압축이 중요하다고 했는데, 압축해서 저장해두면 디스크 내용을 전부 그대로 캐싱해둘 수 있는 경우가 많다.
LZ법 등 일반적인 압축 알고리즘의 경우 텍스트 파일을 대략 절반 정도로 압축할 수 있다. 

캐시를 전제로 한 I/O 줄이는 방법
- 데이터 규모 < 물리 메모리 이면 전부 캐싱할 수 있다.
- 경제적 비용과의 밸런스 고려 -> 현재 일반적인 서버 메모리 32GB 이상

#### 복수 서버로 확장시키기 - 캐시로 해결될 수 없는 규모일 경우
전부 캐싱할 수 없는 구조가 되면
- 복수 서버로 확장시키기
  - CPU 부하분산에는 단순히 늘린다.
  - I/O 분산에는 국소성을 고려한다

#### 단순히 대수만 늘려서는 확장성을 확보할 수 없다
단순히 데이터를 복사해서 대수를 늘리게 되면 애초에 캐시 용량이 부족해서 늘렸는데 그 부족한 부분도 그대로 동일하게 늘려가게 되는 것이다.

단순히 대수를 늘리는 것
- 캐싱할 수 없는 비율은 변함없이 그대로
  - 곧 다시 병목이 된다.

### 강의 10 국소성을 살리는 분산

#### 국소성(locality)을 고려한 분산이란?

캐시 용량을 늘리기 위해 어떻게 하면 여러 대의 서버로 확장시킬 수 있을까
국소성을 고려해서 분산한다.
액세스 패턴을 고려해서 분배하면 액세스 되지 않는 캐시영역을 다른 곳으로 돌릴 수 있다.

국소성을 고려해서 분산
- 액세스 패턴을 고려한 분산
- 캐싱할 수 없는 부분이 사라진다. -> 메모리는 디스크보다 10^6배나 빠르므로 그만큼 덕을 본다.

#### 파티셔닝 - 국소성을 고려한 분산 1

파티셔닝은 한 대 였던 DB 서버를 여러 대의 서버로 분할하는 방법, 
- 테이블 단위 분할 (같이 액세스하는 경우가 많을 때 같은 서버에 위치)
- 테이블 데이터 분할 a~c, d~f, g~i 이런식으로 서버를 나눔 (이 분할의 문제점은 분할의 입도를 크거나 작게 조절할 때 데이터를 한 번 병합해야 한다는 것)

국소성을 고려한 분산의 구체적인 예
- RDBMS의 테이블 단위 분할: 파티셔닝
- 테이블 데이터 분할: a~c, d~f, g~i 
- 용도별로 시스템을 섬으로 나눔

#### 요청 패턴을 섬으로 분할 - 국소성을 고려한 분산 2
HTTP 요청의 User-Agent나 URL 를 보고
사용자과, 검색 봇을 나눔 
- 검색 복은 특성상 오래된 웹 페이지에도 액세스하러 오기 때문에
- 사용자 액세스는 최상위 페이지나 인기 엔트리 페이지 등 최신, 인기 페이지에 집중됨

#### 페이지 캐시를 고려한 운용의 기본 규칙

첫 번째 포인트는 OS 기동 직후에 서버를 투입하지 않음 -> 캐시가 쌓여 있지 않기 떄문에
(OS를 시작해서 기동하면 자주 사용하는 DB의 파일을 cat 해줌) -> 그 후 로드밸런스에 편입

두 번째 포인트는 성능평가나 부하시험 -> 캐시가 최적화된 후에 실시하라

페이지 캐시를 고려한 운용의 기본 규칙
- OS 기동 후에 서버 곧바로 투입X
- 성능평가는 캐시가 최적화 되었을 때

- 분석은 국소성을 고려해서 실시
- 데이터 규모에 맞게 탑재 메모리를 조정 -> 메모리 증설로 대응할 수 없다면 분산

> 부하분산과 OS의 동작원리
> - OS 캐시
> - 멀티스레드나 멀티프로세스
> - 가상 메모리 구조
> - 파일시스템
> 
> 론 요청 분배 LVS 사용법, Apache나 MySQL 미들웨어 사용법, 

## CHAPTER 4 분산을 고려한 MySQL 운용

##### 분산된 시스템 알기 - 애플리케이션을 만들기 전에 알아두어야 할 MySQL 분산 노하우

DB 스케일아웃 전략
- 인덱스의 중요성
- MySQL 분산
- 스케일아웃과 파티셔닝

### 강의 11 인덱스를 올바르게 운용하기 - 분산을 고려한 MySQL 운용의 대전제

#### 분산을 고려한 MySQL 운용, 세 가지 포인트

분산을 고려한 MySQL 운용의 포인트
- OS 캐시 활용
- 인덱스를 적절하게 설정하기
- 확장을 전제로 한 설계

#### OS 캐시 활용

MySQL에서는 처음에 create table로 스키마를 결정, 보통 그다지 신경 쓰지 않고 원하는 대로 설계하는 사람도 많지만
하테나 북마크의 테이블 정도 규모가 되면 상당히 중요히진다.

하테나 북마크의 경우와 같이 3억 레코드 정도 되면 1레코드에 칼럼을 1개, 예를 들어 8바이트 정도의 칼럼을 추가하면 8*3억 바이트만큼의 데이터가 늘어난다.(3G)
스키마를 조금 변경하는 것만으로 기가바이트 단위로 데이터가 증감한다.

대량의 데이터를 저장하려는 테이블은 레코드가 가능한 작아지도록 컴팩트하게 설계해야한다. 정수형 int형은 32비트(4바이트) 문자열이 8비트니까 1바이트
데이터 량을 머리에 넣어두자

OS 캐시 활용
- 전체 데이터 크기에 주의
  - 데이터량 < 물리 메모리를 유지
  - 메모리가 부족할 경우에는 증설
- 스키마 설계가 데이터 크기에 미치는 영향을 고려해야한다.

정규화하면 필요없는 경우에서 뺄때 레코드만큼의 용량이 줄어들 수 있지만 경우에 따라서는 쿼리가 복잡해져서 속도가 떨어지는 경우가 있으므로
속도와 데이터 크기 간 상반관계와 같은 부분을 생각해야 한다.

#### 인덱스의 중요성 - B트리

알고리즘, 데이터 구조에서 탐색을 할 때는 기본적으로 트리가 널리 사용된다.
인텍스는 주로 탐색을 빠르게 하기 위한 것으로, 그 내부 데이터 구조로는 트리가 사용된다.

MySQL의 인덱스는 기본적으로 B+트리라는 데이터 구조다
B트리는 트리를 구성하는 각 노드가 여러 개의 자식을 가질 수 있는 '다분트리' 또한 데이터 삽입이나 삭제를 반복한 경우에도 트리의 형태에 치우침이 생기지 않는
'평형트리'이기도 하다. B트리는 하드디스크 상에 구축하기에 알맞은 데이터 구조이므로 DB에서 자주 사용된다.

트리의 높이는 데이터 건수 n에 대해 반드시 logN이 되므로 탐색시 계산량은 O(logN)이다.

##### 이분트리와 B트리 비교해보기
OS는 디스크에서 데이터를 읽을 때 블록 단위로 읽어냄 다시 말해 디스크를 찾을 때 seek이 발생
B트리의 경우 각 노드를 1블록에 모아서 저장되도록 구성할 수 있으므로 디스크 seek 발생횟수를 노드를 찾아갈 때만으로 최소화할 수 있다.
이분트리는 특정 노드를 모아서 1블록에 저장하는 등의 작업이 어려워서 검색하려면 여기저기 블록에 분산되어 있는 데이터를 읽어야하므로 seek이 많아짐

##### MySQL에서 인덱스 만들기
인덱스의 중요성
- 인덱스=색인
- B+트리
  - 외부기억장치 탐색 시에 Seek횟수를 최소화하는 트리 구조
  - 색인의 계산량: O(n) -> O(log n)

#### 인덱스의 효과
4000만 -> 최대 25.25번

인덱스의 효과
- 계산량 측면에서 개선될 뿐만 아니라 디스크 seek 횟수면에서도 개선된다.
  - 같은 트리라도 B트리와 다른 트리 간에는 서로 다름

##### 인덱스 효과의 예
데이터 건수가 1000건 정도면 트리 순회하는 오버헤드가 클 수 있지만 데이터가 커지면 인덱스 없이는 액세스할 수 없는 상황이 됨

##### 인덱스의 작용 - MySQL의 특성
url과 timestamp 각각 걸려 있으면 검색이나 정렬 중 한쪽 인덱스만 사용하므로
(url, timestamp)를 쌍으로 한 복합 인덱스를 설정해둘 필요가 있음

#### 인덱스가 작용하는지 확인하는 법 - explain 명령
```sql
explain select url from entry where eid = 9615899;
rows 1
```

```sql
explain select url from entry use index(cname) where eid = 9615899;
rows 9615899
```
인덱스가 필요없는 곳에 인덱스를 사용하면 필요없는 탐색이 이루어짐

##### explain 명령에서 속도에 유의하라
using where, using filesort, using temporary 
- using filesort, using temporary 나오면 별로 좋지 않음

##### 인덱스의 간과
O/R 매퍼가 SQL을 작성하는 경우가 있어 실행되는지 간과하고 커밋하는 경우가 많음
-> 감시방안을 늘리는 것이 좋음

### 강의 12 MySQL의 분산 - 확장을 전제로 한 시스템 설계

#### MySQL의 레플리케이션 기능

MySQL에는 기본 기능으로 레플리케이션 기능이 있다.
레플리케이션이란 마스터를 정하고 마스터를 뒤따르는 서버를 정해두면 마스터에 쓴 내용을 슬레이브가 폴링해서 동일한 내용으로 자신을 갱신하는 기능이다.

갱신은 반드시 마스터에서 이뤄지도록 함, 아울러서 슬레이브 앞단에 로드밸런서(LVS 등), MySQL Proxy와 같은 것을 사용한다.

MySQL의 레플리케이션 기능
- 마스터/슬레이브 구성
- 참조 쿼리는 슬레이브로, 갱신 쿼리는 마스터로
- O/R 매퍼로 제어한다.

#### 마스터/슬레이브의 특징 - 참조계열은 확장하고 갱신계열은 확장하지 않는다.

참조계열 쿼리는 슬레이브로 분산하면 되므로 분산할 수 있지만, 갱신계열 쿼리는 분산할 수 없지 않은가?
참조계열 쿼리는 확장을 위해 서버를 늘리면 되는데, 다만 서버를 늘린다고는 해도 앞서 말했듯이 대수를 늘리기보다도 메모리에 맞추는 것이 중요하다.

쓰기보다 읽기가 1000배정도 존재하므로 마스터가 병목이 되어 곤란한 상황이 발생하는 경우는 그렇게 많지 않음

##### 갱신/쓰기계열을 확장하고자 할 떄 - 테이블 분할, key-value 스토어




