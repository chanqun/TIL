# 아파치카프카애플리케이션프로그래밍

링크드인 개발자들이 최초로 배치성 데이터와 실시간 이벤트 스트리밍 데이터를 혼합하여 처리하 는 독특한 로직의 플랫폼을 만들어냈고, 이것이 아파치 카프카의 탄생이다.

- 카프카를 왜 써야 하는가?
- 카프카의 브로커는 어떤 역할을 할까?
- 컨슈머와 프로듀서란 무엇인가?
- 카프카 스트림즈란 무엇인가?
- 카프카 커넥트와 커넥터란 무엇인가?
- 스프링 카프카란 무엇인가?
- 미러메이커2란 무엇인가?
- 클라우드 기반 카프카는 무엇이 있고, 어떻게 사용하는가?

### 1 들어가며

#### 1.1 카프카의 탄생

링크드인 아키텍처는 거대해졌고 소  애플리케이션과 타깃 애플리케이션의 개수가 점점 많아지면서 문제가 생겼다. 
데이터를 전송하는 라인이 기하급수적으로 복잡해지기 시작했다.

카프카는 각각의 애플리케이션끼리 연결하여 데이터를 처리하는 것이 아니라 한 곳에 모아 처리할 수 있도록 중앙집중화했다.
카프카를 통해 웹사이트, 애플리케이션, 센서 등에서 취합한 데이터 스트림을 한 곳에서 실시간으로 관리할 수 있게 된 것이다.

큐에 데이터를 보내는 것이 프로듀서이고 큐에서 데이터를 가져가는 것이 컨슈머다.
카프카는 직렬화, 역직렬화를 통해 ByteArray로 통신하기 때문에 자바에서 선언 가능한 모든 객체를 지원한다.

서버 3대 이상으로 이루어지기 떄문에 안전하고, 데이터를 묶음 단위로 처리하는 배치 전송을 통해 낮은 지연과 높은 데이터 처리량도 가진다.

#### 1.2 빅데이터 파이프라인에서 카프카의 역할

안정적이고 확장성이 높은 데이터 파이프라인(Extracting, Transforming, Loading)을 구축하는 것은 빅데이터를 활용하는 기업에게 필수적

- 높은 처리량 : 묶음 단위, 파티션 분배 병렬추리, 컨슈머 개수를 늘려 시간당 데이터 처리량 늘림
- 확장성 : 데이터가 많아지면 클러스터의 브로커 개수를 자연스럽게 늘려 스케일 아웃할 수 있음
- 영속성 : 카프카는 데이터를 파일 시스템에 저장 (페이지 캐시 사용)
- 고가용성 : 클러스터로 이루어진 카프카는 데이터의 복제를 통해 고가용성의 특징을 가지게 되었

#### 1.3 데이터 레이크 아키텍처와 카프카의 미래
데이터 레이크 아키텍처
(람다 아키텍처, 카파 아키텍처)

로그는 배치 데이터를 스트림을 표현하기에 적합 (변환 기록을 시간 순서대로 기록, 스냅샷 데이터를 저장하지 않아도 배치 데이터를 표현할 수 있음)


### 2 카프카 빠르게 시작해보기

#### 2.1 실습용 카프카 브로커 설치
aws (MSK : Managed Service Kafka, EC2)

분산 코디네이션 서비스를 제공하는 주키퍼

#### 2.2 카프카 커맨드 라인 툴
토픽을 생성하는 2가지 방법
첫 번째 카프카 컨슈머 또는 프로듀서가 카프카 브로커에 생성되지 않은 토픽에 대해 데이터를 요청할 떄
두 번째 커맨드 라인 툴로 명시적으로 토픽을 생성


### 3 카프카 기본 개념 설명

#### 3.1 카프카 브로커, 클러스터, 주키퍼

카프카 브로커는 카프카 클라이언트와 데이터를 주고받기 위해 사용하는 주체이자, 데이터를 분산 저장하여 장애가 발생하더라도
안전하게 사용할 수 있도록 도와주는 애플리케이션이다. 하나의 서버에는 한 개의 카프카 브로커 프로세스가 실행된다.

##### 데이터 저장, 전송
프로듀서로부터 데이터를 전달받으면 카프카 브로커는 프로듀서가 요청한 토픽의 파티션에 데이터를 저장하고 컨슈머가 데이터를 요청하면 파티션에 저장된 데이터를 전달한다.
카프카는 메모리나 데이터베이스에 저장하지 않으며 따로 캐시메모리를 구현하여 사용하지도 않는다.
파일시스템은 일반적으로 처리 속도가 느림 카프카는 페이지 캐시를 사용하여 디스크 입출력 속도를 높여서 이 문제를 해결

##### 데이터 복제, 싱크
데이터 복제는 카프카를 장애 허용 시스템으로 동작하도록 하는 원동력이다. 복제의 이유는 클러스터로 묶인 브로커 중 일부에 장애가 발생하더라도
데이터를 유실하지 않고 안전하게 사용하기 위함이다.

카프카의 데이터 복제는 파티션 단위로 이루어진다. 
프로듀서 또는 컨슈머와 직접 통신하는 파티션을 리더, 나머지 복데 데이터를 가지고 있는 파티션을 팔로워라고 부른다.

##### 컨트롤러
클러스터의 다수 브로커 중 한 대가 컨트롤러의 역할을 한다. 컨트롤러는 다른 브로커들의 상태를 체크하고 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을 재분배한다.
카프카는 지속적으로 데이터를 처리해야 하므로 브로커의 상태가 비정상이라면 빠르게 클러스터에서 뺴내는 것이 중요하다. 만약 컨트롤러 역할을 하는 브로커에 장애가 생기면 다른 브로커가 컨트롤러 역할을 한다.

##### 데이터 삭제
카프카는 다른 메시징 플랫폼과 다르게 컨슈머가 데이터를 가져가더라도 토픽의 데이터는 삭제되지 않는다.
또한, 컨슈머나 프로듀서가 데이터 삭제를 요청할 수도 없다. 오직 브로커만이 데이터를 삭제할 수 있다.
데이터 삭제는 파일 단위로 이루어지는 이 단위를 로그 세그먼트라고 부른다.
닫힌 세그먼트 파일은 옵션에 설정값이 넘으면 삭제된다. 

##### 컨슈머 오프셋 저장
컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기 위해 오프셋을 커밋한다.

##### 코디네이터
클러스터의 다수 브로커 중 한 대는 코디네이터의 역할을 수행한다. 
코디네이터는 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역할을 한다. 
컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않은 파티션을 정상 동작하는 컨슈머로 할당하여 끊임없이 데이터가 처리되도록 도와준다.


#### 3.2 토픽과 파티션
토픽은 카프카에서 데이터를 구분하기 위해 사용하는 단위이다.

토픽은 1개 이상의 파티션을 소유하고 있다. 파티션에는 프로듀서가 보낸 데이터들이 들어가 저장되는데 이 데이터를 레코드라고 부른다.
파티션은 카프카의 병렬처리의 핵심으로써 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭된다.
파티션은 큐와 비슷한 구조, 파티션의 레코드는 컨슈머가 가져가는 것과 별개로 관리되어 여러 컨슈머 그룹들이 토픽의 데이터를 여러번 가져갈 수 있음

의미 있는 토픽 이름 작명 방
- <환경>.<팀-명>.<애플리케이션-명>.<메시지-타입>
ex) prd.marketing-team.sms-platform.json
- <프로젝트-명>.<서비스-명>.<환경>.<이벤트-명>
ex) commerce.payment.prd.notification
- <환경>.<서비스-명>.<JIRA-번호>.<메시지-타입> 
ex) dev.email-sender.jira-1234.email-vo-custom
- <카프카-클러스터-명>.<환경>.<서비스-명>.<메시지-타입>
ex) aws-kafka.live.marketing-platform.json

#### 3.3 레코드
레코드는 타임스탬프, 메시지 키, 메시지 값, 오프셋으로 구성되어 있다.
프로듀서가 생성한 레코드가 브로커로 전송되면 오프셋과 타임스탬프가 지정되어 저장된다.
브로커에 한번 적재된 레코드는 수정할 수 없고 로그 리텐션 기간 또는 용량에 따라서만 삭제된다.

#### 3.4 카프카 클라이언트

##### 3.4.1 프로듀서 API

카프카 클러스터에 명령을 내리거나 데이터를 송수신하기 위해 카프카 클라이언트 라이브러 리는 카프카 프로듀서, 컨슈머, 어드민 클라이언트를 제공하는 카프카 클라이언트를 사용하여 애플리케이션을 개발한다.
카프카 클라이언트는 라이브러리이기 때문에 자체 라이프사이클을 가진 프레임워크나 애플리케이션 위에서 구현하고 실행해야 한다.

프로듀서 중요 개념
프로듀서는 카프카 브로커로 데이터를 전송할 때 내부적으로 파티셔너, 배치 생성 단계를 거친다.

![kafka1.png](../image/apachekafka1.png)

##### 3.4.2 컨슈머 API
프로듀서가 전송한 데이터는 카프카 브로커에 적재된다. 
컨슈머는 적재된 데이터를 사용하기 위해 브로커로부터 데이터를 가져와서 필요한 처리를 한다.
예를 들어, 마케팅 문자를 고객에 게 보내는 기능이 있다면 컨슈머는 토픽으로부터 고객 데이터를 가져와서 문자 발송 처리를 하게 된다.

##### 3.4.3 어드민

#### 3.5 카프카 스트림즈
카프카 스트림즈는 토픽에 적재된 데이터를 실시간으로 변환하여 다른 토픽에 적재하는 라이브러리이다.
스트림즈 애플리케이션 또는 카프카 브로 커의 장애가 발생하더라도 정확히 한번할 수 있도록 장애 허용 시스템(fault tolerant system)을 가지고 있어서 데이터 처리 안정성이 매우 뛰어나다.

#### 3.5.1 스트림즈 DSL
스트림즈DSL에는 레코드의 흐름을 추상화한 3가지 개 념인 KStream, KTable, GlobalKTable이 있다.

KStream
KStream은 레코드의 흐름을 표현한 것으로 메시지 키와 메시지 값으로 구성되어 있다. KStream 으로 데이터를 조회하면 토픽에 존재하는(또는 KStream에 존재하는) 모든 레코드가 출력된다.

KTable
KTable은 KStream과 다르게 메시지 키를 기준으로 묶어서 사용한다. KStream은 토픽의 모든 레코드를 조회할 수 있지만 KTable은 유니크한 메시지 키를 기준으로 가장 최신 레코드를 사용한다.

GlobalKTable
GlobalKTable은 KTable과 동일하게 메시지 키를 기준으로 묶어서 사용된다. 그러나 KTable로 선언된 토픽은 1개 파티션이 1개 태스크에 할당되어 사용되고, GlobalKTable 로 선언된 토픽은 모든 파티션 데이터가 각 태스크에 할당되어 사용된다는 차이점이 있다.

#### 3.6 카프카 커넥트
카프카 커넥트는 카프카 오픈소스에 포함된 툴 중 하나로 데이터 파이프라인 생성 시 반복 작업을 줄이고 효율적인 전송을 이루기 위한 애플리케이션이다.

파이프라인 생성 시 자주 반복되는 값들을 파라미터로 받는 커넥터를 코드로 작성하면 이후에 파이프라인을 실행할 때는 코드를 작성할 필요가 없기 때문이다.

##### 3.6.1 소스 커넥터
소스 커넥터는 소스 애플리케이션 또는 소스 파일로부터 데이터를 가져와 토픽으로 넣는 역할을 한다.

##### 3.6.2 싱크 커넥터
싱크 커넥터는 토픽의 데이터를 타깃 애플리케이션 또는 타깃 파일로 저장하는 역할을 한다.

#### 3.7 카프카 미러메이커2
카프카 미러메이커2는 서로 다른 두 개의 카프카 클러스터 간에 토픽을 복제하는 애플리케이션이다.


### 4 카프카 상세 개념 설명 

#### 4.1 토픽과 파티션

